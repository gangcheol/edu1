{"title":"01. intro","markdown":{"yaml":{"title":"01. intro","author":"GC","date":"03/26/24"},"headingText":"Intro","containsRefs":false,"markdown":"\n\n\n`-` 음...\n\n* 모집단, 표본, 가설 검정, 기계학습... 중심극한정리???\n\n* 그래서 이런 것들에 대해 간략하게 설명 후, 방향성 선택!\n\n* 일단, 해당 수업의 목적을 제가 잘 모르겟어서... R, python을 활용하여 통계분석을 한다는 건지, 아니면 예측모형을 주로 공부한다는 건지...(두 가지 다인가...???)\n\n# key elemenets in business analytics\n\n`1` Right questions\n\n`2` Computation skills(통계분석, 선형대수학...등등)\n\n`3` Visualizatioin(R, python, taebleau 등을 활용한 결과 시각화 능력)\n\n`4` Communication skills\n\n# Analytics tools\n\n`-` 통계에서 가장 많이 쓰는 tool\n\n`-` 최근에는 머신러닝, 딥러닝 분야에서도 적용이 되고 있음(특히 의학, 생명공학)\n\n`-` 개인적인 생각 : `통계분석`, `회귀분석` 쪽에서는 R이 훨씬 가독성이 좋음, `머신러닝`, `딥러닝`은 python으로 개발이 너무 잘 되어있어서 아직 장벽을 넘긴 힘든 것 같다..\n\n### ex1. 데이터 로드 및 저장\n\n#### R\n\n`1` 라이브러리 불러오기\n\n`2` 데이터 로드 및 저장\n\n* fread가 좀 더 빠르긴 하지만, 종종 에러가 발생하고, 그 에러를 찾는데 시간이 많이 걸려서 전 선호하지 않습니다.\n\n* read.csv : R에서 기본적으로 제공하는 데이터 로드 함수\n\n* read_csv : `readr`패키지에서 제공하는 데이터 로드 함수\n\n* fread : `data.table` 패키지에서 제공하는 데이터 로드 함수\n\n`-` 불러온 데이터에서 `Species`가 `setosa`인 행만 추출하여 다른 `iris2`라는 파일로 저장해보자\n\n`-` 저장한 데이터를 다시 불러와서 확인\n\n#### python\n\n`-` 패키지 설치 : pandas\n\n* 데이터 로드, 핸들링 등 데이터를 원하는 형태로 가공하기 위한 python 모듈\n\n***\n\n### data exploration\n\n`-` 일반적으로 Business analytics에서는 설명변수 $X$와 반응변수 또는 결과변수인 $Y$ 의 관계에 대한 설명을 원한다.\n\n`-` GIGO(Garbage in, Garbage out) : 쓰레기가 들어가면, 쓰레기가 나온다.\n\n* 우리가 $X$와 $Y$의 관계를 규명하는데 방해되는 데이터, 또는 애초에 데이터 자체에 이상치, 결측치들이 너무 많아 분석 자체를 할 수 없는 데이터....\n\n`-` 그래서, 탐색적자료분석(EDA, Exploratory Data Analysis)은 모든 분석에 있어서 필수적으로 거쳐야한다.\n\n* 이상치, 결측치 대체, 표준화, 정규화 등등 필요에 따라 적절히 데이터를 가공할 줄 아는 능력이 필요함\n\n#### EDA in R\n\n방법 1. summary함수 : 데이터에 대한 요약값 출력\n\n방법 2. apply함수\n\n`-` 방법3. plot\n\n<center><img src = \"1-1.png\"></center>\n\n#### EDA in python\n\n### data processing\n\n#### R\n\n`1` Merge : key값을 기준으로 데이터프레임을 병합하는 방법\n\n* Left join : 왼쪽 데이터 프레임의 모든 행의 결과를 포함\n\n* Right join : 오른쪽 데이터 프레임의 모든 행의 결과를 포함\n\n* inner join : 왼쪽, 오른쪽에서 key값이 모두 존재하는 행만 병합\n\n* outter join : 그냥 전부 병합\n\n***\n\n`2` Conditioning (filtering)\n\n* 강의에서 언급한 전처리 방법은 전 선호 하지 않아요. \n\n`2` 컬럼 생성 & 결측치 대체\n\n`-` class별 평균값 생성 후 붙이기\n\n`-` 결측치 대체\n\n#### python\n\n`1` 데이터 필터링\n\n`2` 컬럼 생성\n\n`3` 결측치 대체\n\n***\n\n### data Visualization\n\n#### R\n\n#### python\n\n***\n\n# Statistical Modeling\n\n## Supervised Learning\n\n`1` 설명변수 $X = (x_1,x_2,\\dots x_p)$로 부터 target변수인 $Y$를 예측하는 것!\n\n$$y \\approx \\beta_1x + \\beta_0$$\n\n`2` 가장 중요한 개념!\n\n$$\\text{총 제곱합} = \\text{회귀제곱합} + \\text{잔차제곱합}$$\n\n$$\\sum{(y-\\bar y)}^2 = \\sum{(\\hat y - \\bar y)}^2 + \\sum{( y - \\hat y)}^2 $$\n\n$$\\text{SST} = \\text{SSR} + \\text{SSE}$$\n\n`3` 일반적으로 $\\text{SSR}$ `회귀식으로 설명할 수 있는 변동`이라고 하며, 회귀분석 시 가장 관심있는 부분이다.\n\n`4` 총 제곱합 $\\text{SST}$는 변하지 않는 값이므로, `SSR`이 커지면 `SSE`즉, 예측값과 실제값의 차이는 줄어들게 된다.\n\n`5` 이는, 주어진 데이터로부터 우리가 적합한 회귀직선이 어떤 현상을 잘 설명하고 있다고 볼 수 있다.\n\n`6` 그러면, 회귀모형 적합 후, 우리는 무엇을 검토해야 하나?\n\n* 모형 내의 개별 회귀계수에 대한 검정(`t통계량, p-value확인`)\n\n$$H_0 : \\beta_1 =0 \\quad\\text{ vs } \\quad H_1  : \\text{not } H_0$$\n\n* 모형에 설명력인 결정계수 값 $R^2$값 확인, 설명변수의 수가 많아질 경우 $adj-R^2$값을 확인\n\n$$R^2 = \\frac{SSR}{SST} = \\frac{1-SSE}{SST}$$\n\n$$R^2_{adj} = \\frac{SSR\\,/\\,(n-(p+1))}{SST\\,/\\,(n-1)} $$\n\n* 회귀모형이 통계적을 유의한가?(`F-통계량, p-value확인`)\n\n$$H_0 : \\beta_1 = \\beta_2 = \\beta_3 = \\dots 0 \\quad\\text{ vs } \\quad H_1  : \\text{not } H_0$$\n\n* 잔차 plot을 통한 모형 진단\n\n### ex1. cars(Simple Linear regression)\n\n`-` 우리는 주어진 데이터로부터 아래왜 같은 현상을 예측하고 싶음\n\n$$\\text{dist} = \\beta_1\\times\\text{speed} + \\beta_0$$\n\n`-` 즉, 속력에 따른 거리를 예측하기 위한 $\\beta_1, \\beta_0$를 추정! $\\to$ $(\\hat{\\beta_1}, \\hat{\\beta_0})$\n\n`-` 일반적으로, 알려진 단순선형회귀분석에서의 $(\\hat{\\beta_1}, \\hat{\\beta_0})$을 구하는 방법!\n\n$$\\hat {\\beta_0} = \\bar y - \\hat {\\beta_1}\\bar x$$\n\n$$\\hat {\\beta_1} = \\frac{S_{xy}}{S_{xx}} = \\frac{\\sum(x-\\bar x)(y-\\bar y)}{\\sum(x-\\bar x)^2}$$\n\n`-` 공식유도법(나중에 시간되면 한번 풀어보세요!)\n\n<center><img src = \"1-2.png\" width = 600></center>\n\n`-` 실제로 저렇게 계산한 값과 R에서 회귀분석을 적합한 값이 일치한지 확인해보자\n\n`-` 즉, 이론상으로 속도에 따른 거리는 다음과 같이 설명할 수 있다\n\n$$\\text{dist} \\approx  3.9324 \\times \\text{spped} -17.579... $$\n\n`-` 결과해석\n\n* Residuals : 실제값과 예측값의 차이\n\n$$\\varepsilon_i = \\hat{y_i} - y_i, \\quad \\varepsilon_i \\sim N(0, \\sigma^2)$$\n\n* 잔차 제곱합은 다음과 같이 표현한다.\n\n$$SSE =  \\sum_{i=1}^{n} \\varepsilon^2$$\n\n* extra. subplots 그리는법\n\n* p-value? 검정통계량의 근거하여 적합한 모형의 유의미성을 검증하는 척도 \n\n#### 결과해석\n\n`1` 추정된 회귀계수 $\\hat{\\beta_1},\\hat{\\beta_0}$는 t-검정통계량의 근거한 p-value값을 보았을 때 0.05보다 작아 통계적으로 유의하다.\n\n`2` 결정계수값을 살펴본 결과 적합한 모형은 65% 정도의 설명력을 가지고 있다.\n\n`3` 또한, `F-통계량`의 근거한 `p-value`값을 보아도 생성된 모델은 통계적으로 유의하다.\n\n`4` 잔차 plot을 그려본 결과 오차항의 정규성과 독립성 가정에 위배되지 않았음\n\n`5` 따라서, 우리가 적합한 모델은 속도에 따른 자동차의 주행거리를 설명하기에 적합한 모형이라고 할 수 있다.\n\n***\n\n### ex2. adult(logistic)\n\n`-` 로지스틱 모형은 target 변수인 $y$에 대한 직접적 모형화가 아닌 $y$가 특정 범주에 포함될 확률을 모형화한다.\n\n`-` 임계치(threshole)를 정하고 어떤 범주에 포함될 확률이 임계치보다 높으면 0 or 1로 예측하는 분류 모형이다. (이진분류에서!)\n\n#### 모형 유도\n\nstep1 : 0과 1사이의 값으로 예측해 주는 모형 설계\n\n$$P(X) = \\frac{exp(\\beta_0+\\beta_1X)}{1+exp(\\beta_0+\\beta_1X)}, \\quad \\in (0,1)$$\n\nstep2. odds, 배팅을 하는 분야에서 확률 대신 많이 쓰이는 측도\n\n$$\\text{odds} = \\frac{P(X)}{1-P(x)}= {exp(\\beta_0 + \\beta_1X)}, \\quad \\in(0, \\infty)$$\n\nstep3. logit, 배팅을하는 분야에서 확률 대신 많이 쓰이는 측도\n\n$$\\text{logit} = \\log{\\frac{P(X)}{1-P(x)}}  = \\beta_0 + \\beta_1 x, \\quad \\in (-\\infty, \\infty)$$\n\n즉, 우리는 로짓에서 보이는 $\\beta_0, \\beta_1$을 추정하는 것임\n\n#### 실습, 주식 데이터\n\n`-`데이터  설명\n\n* lag$_i$ : i번째 전 날의 smarket 주식 종가\n\n* today : 오늘 주식 종가\n\n* Direction : 주식이 올라갔는지, 떨어졌는지\n\n* Volume : 거래량\n\n`1` 데이터셋 분할 7:3으로 분할\n\n`2` 모형 적합\n\n`3` 예측\n\n#### 정밀도, 재현율, 정확도\n\n`-` 위 네 가지는, 분류 모델의 성능 평가시 사용되는 척도이며 처음 접하는 사람들이 많이 헷갈려한다.\n\n`-` 위 예제는 4가지 지표에서 뛰어난 성능을 보이나 그렇지 않은 경우가 존재한다면?\n\n`-` 정확도(accuracy)를 구해보자\n\n`-` 오, 괜찮은 것 같다?\n\n* 그러나 여기에는 함정이 존재한다.(재현율)\n\n* 어라? 전체 B중에 예측모델이 B라고 예측한 것은 0.24..밖에 안되네?\n* 기업의 입장에서 보았을 때, 정확도보단 재현율이 더 중요한 지표임\n* 즉, 실제 참인 것 중에 예측모델이 참이라고 예측한 비율이 낮은 경우가 발생할 수 있음\n\n`-` 정밀도 : 모델이 참이라고 예측한 것 중, 실제 참인 것의 비율\n\n`-` 즉, 우리가 분류모델을 설계하고, 에측 성능을 판단할 때 단순히 정확도만 보고 판단하면 안 된다는 것!\n\n***\n\n## Unsupervised Learning\n\n`-` 설명변수 $X=(x_1, x_2, \\dots)$로 부터 비슷한 성질을 갖는 녀석들끼리 한 집단으로 묶는 것\n\n`-` 대표적인 알고리즘 : kmeans, dbscan, hdbscan 등등\n\n### k-means\n\n`1`주어진 데이터를 k개의 클러스터로 묶는 알고리즘, 각 클러스터와 거리 차이의 분산을 최소화 하는 방식으로 동작\n\n`2` 허나 군집의 수, 가중치와 거리 정의가 어려우며, 사전에 주어진 목적이 없으므로 결과 해석이 어려움.\n\n`3` 또한 잡음이나 이상값의 영향을 받으며 초기 군집 수를 결정해야 한다는 단점이 있다.\n\n`-` 만약, 우리가 생성한 군집이 잘 생성되었다면? 완쪽과 같은 분포로 군집이 형성되어야 한다.\n\n***\n\n# do next\n\n`-` 통계 용어 설명\n\n`-` 머신러닝 이론 및 실습 (1) 선형회귀부터 ~ 랜덤포레스트까지!\n\n`-` 겁먹지 말구 잘해봅시당!\n","srcMarkdownNoYaml":"\n\n# Intro\n\n`-` 음...\n\n* 모집단, 표본, 가설 검정, 기계학습... 중심극한정리???\n\n* 그래서 이런 것들에 대해 간략하게 설명 후, 방향성 선택!\n\n* 일단, 해당 수업의 목적을 제가 잘 모르겟어서... R, python을 활용하여 통계분석을 한다는 건지, 아니면 예측모형을 주로 공부한다는 건지...(두 가지 다인가...???)\n\n# key elemenets in business analytics\n\n`1` Right questions\n\n`2` Computation skills(통계분석, 선형대수학...등등)\n\n`3` Visualizatioin(R, python, taebleau 등을 활용한 결과 시각화 능력)\n\n`4` Communication skills\n\n# Analytics tools\n\n`-` 통계에서 가장 많이 쓰는 tool\n\n`-` 최근에는 머신러닝, 딥러닝 분야에서도 적용이 되고 있음(특히 의학, 생명공학)\n\n`-` 개인적인 생각 : `통계분석`, `회귀분석` 쪽에서는 R이 훨씬 가독성이 좋음, `머신러닝`, `딥러닝`은 python으로 개발이 너무 잘 되어있어서 아직 장벽을 넘긴 힘든 것 같다..\n\n### ex1. 데이터 로드 및 저장\n\n#### R\n\n`1` 라이브러리 불러오기\n\n`2` 데이터 로드 및 저장\n\n* fread가 좀 더 빠르긴 하지만, 종종 에러가 발생하고, 그 에러를 찾는데 시간이 많이 걸려서 전 선호하지 않습니다.\n\n* read.csv : R에서 기본적으로 제공하는 데이터 로드 함수\n\n* read_csv : `readr`패키지에서 제공하는 데이터 로드 함수\n\n* fread : `data.table` 패키지에서 제공하는 데이터 로드 함수\n\n`-` 불러온 데이터에서 `Species`가 `setosa`인 행만 추출하여 다른 `iris2`라는 파일로 저장해보자\n\n`-` 저장한 데이터를 다시 불러와서 확인\n\n#### python\n\n`-` 패키지 설치 : pandas\n\n* 데이터 로드, 핸들링 등 데이터를 원하는 형태로 가공하기 위한 python 모듈\n\n***\n\n### data exploration\n\n`-` 일반적으로 Business analytics에서는 설명변수 $X$와 반응변수 또는 결과변수인 $Y$ 의 관계에 대한 설명을 원한다.\n\n`-` GIGO(Garbage in, Garbage out) : 쓰레기가 들어가면, 쓰레기가 나온다.\n\n* 우리가 $X$와 $Y$의 관계를 규명하는데 방해되는 데이터, 또는 애초에 데이터 자체에 이상치, 결측치들이 너무 많아 분석 자체를 할 수 없는 데이터....\n\n`-` 그래서, 탐색적자료분석(EDA, Exploratory Data Analysis)은 모든 분석에 있어서 필수적으로 거쳐야한다.\n\n* 이상치, 결측치 대체, 표준화, 정규화 등등 필요에 따라 적절히 데이터를 가공할 줄 아는 능력이 필요함\n\n#### EDA in R\n\n방법 1. summary함수 : 데이터에 대한 요약값 출력\n\n방법 2. apply함수\n\n`-` 방법3. plot\n\n<center><img src = \"1-1.png\"></center>\n\n#### EDA in python\n\n### data processing\n\n#### R\n\n`1` Merge : key값을 기준으로 데이터프레임을 병합하는 방법\n\n* Left join : 왼쪽 데이터 프레임의 모든 행의 결과를 포함\n\n* Right join : 오른쪽 데이터 프레임의 모든 행의 결과를 포함\n\n* inner join : 왼쪽, 오른쪽에서 key값이 모두 존재하는 행만 병합\n\n* outter join : 그냥 전부 병합\n\n***\n\n`2` Conditioning (filtering)\n\n* 강의에서 언급한 전처리 방법은 전 선호 하지 않아요. \n\n`2` 컬럼 생성 & 결측치 대체\n\n`-` class별 평균값 생성 후 붙이기\n\n`-` 결측치 대체\n\n#### python\n\n`1` 데이터 필터링\n\n`2` 컬럼 생성\n\n`3` 결측치 대체\n\n***\n\n### data Visualization\n\n#### R\n\n#### python\n\n***\n\n# Statistical Modeling\n\n## Supervised Learning\n\n`1` 설명변수 $X = (x_1,x_2,\\dots x_p)$로 부터 target변수인 $Y$를 예측하는 것!\n\n$$y \\approx \\beta_1x + \\beta_0$$\n\n`2` 가장 중요한 개념!\n\n$$\\text{총 제곱합} = \\text{회귀제곱합} + \\text{잔차제곱합}$$\n\n$$\\sum{(y-\\bar y)}^2 = \\sum{(\\hat y - \\bar y)}^2 + \\sum{( y - \\hat y)}^2 $$\n\n$$\\text{SST} = \\text{SSR} + \\text{SSE}$$\n\n`3` 일반적으로 $\\text{SSR}$ `회귀식으로 설명할 수 있는 변동`이라고 하며, 회귀분석 시 가장 관심있는 부분이다.\n\n`4` 총 제곱합 $\\text{SST}$는 변하지 않는 값이므로, `SSR`이 커지면 `SSE`즉, 예측값과 실제값의 차이는 줄어들게 된다.\n\n`5` 이는, 주어진 데이터로부터 우리가 적합한 회귀직선이 어떤 현상을 잘 설명하고 있다고 볼 수 있다.\n\n`6` 그러면, 회귀모형 적합 후, 우리는 무엇을 검토해야 하나?\n\n* 모형 내의 개별 회귀계수에 대한 검정(`t통계량, p-value확인`)\n\n$$H_0 : \\beta_1 =0 \\quad\\text{ vs } \\quad H_1  : \\text{not } H_0$$\n\n* 모형에 설명력인 결정계수 값 $R^2$값 확인, 설명변수의 수가 많아질 경우 $adj-R^2$값을 확인\n\n$$R^2 = \\frac{SSR}{SST} = \\frac{1-SSE}{SST}$$\n\n$$R^2_{adj} = \\frac{SSR\\,/\\,(n-(p+1))}{SST\\,/\\,(n-1)} $$\n\n* 회귀모형이 통계적을 유의한가?(`F-통계량, p-value확인`)\n\n$$H_0 : \\beta_1 = \\beta_2 = \\beta_3 = \\dots 0 \\quad\\text{ vs } \\quad H_1  : \\text{not } H_0$$\n\n* 잔차 plot을 통한 모형 진단\n\n### ex1. cars(Simple Linear regression)\n\n`-` 우리는 주어진 데이터로부터 아래왜 같은 현상을 예측하고 싶음\n\n$$\\text{dist} = \\beta_1\\times\\text{speed} + \\beta_0$$\n\n`-` 즉, 속력에 따른 거리를 예측하기 위한 $\\beta_1, \\beta_0$를 추정! $\\to$ $(\\hat{\\beta_1}, \\hat{\\beta_0})$\n\n`-` 일반적으로, 알려진 단순선형회귀분석에서의 $(\\hat{\\beta_1}, \\hat{\\beta_0})$을 구하는 방법!\n\n$$\\hat {\\beta_0} = \\bar y - \\hat {\\beta_1}\\bar x$$\n\n$$\\hat {\\beta_1} = \\frac{S_{xy}}{S_{xx}} = \\frac{\\sum(x-\\bar x)(y-\\bar y)}{\\sum(x-\\bar x)^2}$$\n\n`-` 공식유도법(나중에 시간되면 한번 풀어보세요!)\n\n<center><img src = \"1-2.png\" width = 600></center>\n\n`-` 실제로 저렇게 계산한 값과 R에서 회귀분석을 적합한 값이 일치한지 확인해보자\n\n`-` 즉, 이론상으로 속도에 따른 거리는 다음과 같이 설명할 수 있다\n\n$$\\text{dist} \\approx  3.9324 \\times \\text{spped} -17.579... $$\n\n`-` 결과해석\n\n* Residuals : 실제값과 예측값의 차이\n\n$$\\varepsilon_i = \\hat{y_i} - y_i, \\quad \\varepsilon_i \\sim N(0, \\sigma^2)$$\n\n* 잔차 제곱합은 다음과 같이 표현한다.\n\n$$SSE =  \\sum_{i=1}^{n} \\varepsilon^2$$\n\n* extra. subplots 그리는법\n\n* p-value? 검정통계량의 근거하여 적합한 모형의 유의미성을 검증하는 척도 \n\n#### 결과해석\n\n`1` 추정된 회귀계수 $\\hat{\\beta_1},\\hat{\\beta_0}$는 t-검정통계량의 근거한 p-value값을 보았을 때 0.05보다 작아 통계적으로 유의하다.\n\n`2` 결정계수값을 살펴본 결과 적합한 모형은 65% 정도의 설명력을 가지고 있다.\n\n`3` 또한, `F-통계량`의 근거한 `p-value`값을 보아도 생성된 모델은 통계적으로 유의하다.\n\n`4` 잔차 plot을 그려본 결과 오차항의 정규성과 독립성 가정에 위배되지 않았음\n\n`5` 따라서, 우리가 적합한 모델은 속도에 따른 자동차의 주행거리를 설명하기에 적합한 모형이라고 할 수 있다.\n\n***\n\n### ex2. adult(logistic)\n\n`-` 로지스틱 모형은 target 변수인 $y$에 대한 직접적 모형화가 아닌 $y$가 특정 범주에 포함될 확률을 모형화한다.\n\n`-` 임계치(threshole)를 정하고 어떤 범주에 포함될 확률이 임계치보다 높으면 0 or 1로 예측하는 분류 모형이다. (이진분류에서!)\n\n#### 모형 유도\n\nstep1 : 0과 1사이의 값으로 예측해 주는 모형 설계\n\n$$P(X) = \\frac{exp(\\beta_0+\\beta_1X)}{1+exp(\\beta_0+\\beta_1X)}, \\quad \\in (0,1)$$\n\nstep2. odds, 배팅을 하는 분야에서 확률 대신 많이 쓰이는 측도\n\n$$\\text{odds} = \\frac{P(X)}{1-P(x)}= {exp(\\beta_0 + \\beta_1X)}, \\quad \\in(0, \\infty)$$\n\nstep3. logit, 배팅을하는 분야에서 확률 대신 많이 쓰이는 측도\n\n$$\\text{logit} = \\log{\\frac{P(X)}{1-P(x)}}  = \\beta_0 + \\beta_1 x, \\quad \\in (-\\infty, \\infty)$$\n\n즉, 우리는 로짓에서 보이는 $\\beta_0, \\beta_1$을 추정하는 것임\n\n#### 실습, 주식 데이터\n\n`-`데이터  설명\n\n* lag$_i$ : i번째 전 날의 smarket 주식 종가\n\n* today : 오늘 주식 종가\n\n* Direction : 주식이 올라갔는지, 떨어졌는지\n\n* Volume : 거래량\n\n`1` 데이터셋 분할 7:3으로 분할\n\n`2` 모형 적합\n\n`3` 예측\n\n#### 정밀도, 재현율, 정확도\n\n`-` 위 네 가지는, 분류 모델의 성능 평가시 사용되는 척도이며 처음 접하는 사람들이 많이 헷갈려한다.\n\n`-` 위 예제는 4가지 지표에서 뛰어난 성능을 보이나 그렇지 않은 경우가 존재한다면?\n\n`-` 정확도(accuracy)를 구해보자\n\n`-` 오, 괜찮은 것 같다?\n\n* 그러나 여기에는 함정이 존재한다.(재현율)\n\n* 어라? 전체 B중에 예측모델이 B라고 예측한 것은 0.24..밖에 안되네?\n* 기업의 입장에서 보았을 때, 정확도보단 재현율이 더 중요한 지표임\n* 즉, 실제 참인 것 중에 예측모델이 참이라고 예측한 비율이 낮은 경우가 발생할 수 있음\n\n`-` 정밀도 : 모델이 참이라고 예측한 것 중, 실제 참인 것의 비율\n\n`-` 즉, 우리가 분류모델을 설계하고, 에측 성능을 판단할 때 단순히 정확도만 보고 판단하면 안 된다는 것!\n\n***\n\n## Unsupervised Learning\n\n`-` 설명변수 $X=(x_1, x_2, \\dots)$로 부터 비슷한 성질을 갖는 녀석들끼리 한 집단으로 묶는 것\n\n`-` 대표적인 알고리즘 : kmeans, dbscan, hdbscan 등등\n\n### k-means\n\n`1`주어진 데이터를 k개의 클러스터로 묶는 알고리즘, 각 클러스터와 거리 차이의 분산을 최소화 하는 방식으로 동작\n\n`2` 허나 군집의 수, 가중치와 거리 정의가 어려우며, 사전에 주어진 목적이 없으므로 결과 해석이 어려움.\n\n`3` 또한 잡음이나 이상값의 영향을 받으며 초기 군집 수를 결정해야 한다는 단점이 있다.\n\n`-` 만약, 우리가 생성한 군집이 잘 생성되었다면? 완쪽과 같은 분포로 군집이 형성되어야 한다.\n\n***\n\n# do next\n\n`-` 통계 용어 설명\n\n`-` 머신러닝 이론 및 실습 (1) 선형회귀부터 ~ 랜덤포레스트까지!\n\n`-` 겁먹지 말구 잘해봅시당!\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":true,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":true,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"toc":true,"output-file":"2024-03-28-01. intro.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.4.551","theme":"minty","editor":"visual","code-copy":true,"title-block-banner":true,"title":"01. intro","author":"GC","date":"03/26/24"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}