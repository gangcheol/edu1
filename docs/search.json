[
  {
    "objectID": "posts/2024-03-28-01. intro.html",
    "href": "posts/2024-03-28-01. intro.html",
    "title": "01. intro",
    "section": "",
    "text": "- 음…\n\n모집단, 표본, 가설 검정, 기계학습… 중심극한정리???\n그래서 이런 것들에 대해 간략하게 설명 후, 방향성 선택!\n일단, 해당 수업의 목적을 제가 잘 모르겟어서… R, python을 활용하여 통계분석을 한다는 건지, 아니면 예측모형을 주로 공부한다는 건지…(두 가지 다인가…???)",
    "crumbs": [
      "Posts",
      "01. intro"
    ]
  },
  {
    "objectID": "posts/2024-03-28-01. intro.html#supervised-learning",
    "href": "posts/2024-03-28-01. intro.html#supervised-learning",
    "title": "01. intro",
    "section": "Supervised Learning",
    "text": "Supervised Learning\n1 설명변수 \\(X = (x_1,x_2,\\dots x_p)\\)로 부터 target변수인 \\(Y\\)를 예측하는 것!\n\\[y \\approx \\beta_1x + \\beta_0\\]\n2 가장 중요한 개념!\n\\[\\text{총 제곱합} = \\text{회귀제곱합} + \\text{잔차제곱합}\\]\n\\[\\sum{(y-\\bar y)}^2 = \\sum{(\\hat y - \\bar y)}^2 + \\sum{( y - \\hat y)}^2 \\]\n\\[\\text{SST} = \\text{SSR} + \\text{SSE}\\]\n3 일반적으로 \\(\\text{SSR}\\) 회귀식으로 설명할 수 있는 변동이라고 하며, 회귀분석 시 가장 관심있는 부분이다.\n4 총 제곱합 \\(\\text{SST}\\)는 변하지 않는 값이므로, SSR이 커지면 SSE즉, 예측값과 실제값의 차이는 줄어들게 된다.\n5 이는, 주어진 데이터로부터 우리가 적합한 회귀직선이 어떤 현상을 잘 설명하고 있다고 볼 수 있다.\n6 그러면, 회귀모형 적합 후, 우리는 무엇을 검토해야 하나?\n\n모형 내의 개별 회귀계수에 대한 검정(t통계량, p-value확인)\n\n\\[H_0 : \\beta_1 =0 \\quad\\text{ vs } \\quad H_1  : \\text{not } H_0\\]\n\n모형에 설명력인 결정계수 값 \\(R^2\\)값 확인, 설명변수의 수가 많아질 경우 \\(adj-R^2\\)값을 확인\n\n\\[R^2 = \\frac{SSR}{SST} = \\frac{1-SSE}{SST}\\]\n\\[R^2_{adj} = \\frac{SSR\\,/\\,(n-(p+1))}{SST\\,/\\,(n-1)} \\]\n\n회귀모형이 통계적을 유의한가?(F-통계량, p-value확인)\n\n\\[H_0 : \\beta_1 = \\beta_2 = \\beta_3 = \\dots 0 \\quad\\text{ vs } \\quad H_1  : \\text{not } H_0\\]\n\n잔차 plot을 통한 모형 진단\n\n\nex1. cars(Simple Linear regression)\n\nlibrary(tidyverse)\n\n-- Attaching core tidyverse packages ---------------------------------------------------------------- tidyverse 2.0.0 --\nv dplyr     1.1.4     v readr     2.1.5\nv forcats   1.0.0     v stringr   1.5.0\nv ggplot2   3.4.2     v tibble    3.2.1\nv lubridate 1.9.3     v tidyr     1.3.1\nv purrr     1.0.2     \n-- Conflicts ---------------------------------------------------------------------------------- tidyverse_conflicts() --\nx dplyr::filter() masks stats::filter()\nx dplyr::lag()    masks stats::lag()\ni Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\nhead(cars)\n\n\n\nA data.frame: 6 × 2\n\n\n\nspeed\ndist\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n\n\n\n\n1\n4\n2\n\n\n2\n4\n10\n\n\n3\n7\n4\n\n\n4\n7\n22\n\n\n5\n8\n16\n\n\n6\n9\n10\n\n\n\n\n\n\n- 우리는 주어진 데이터로부터 아래왜 같은 현상을 예측하고 싶음\n\\[\\text{dist} = \\beta_1\\times\\text{speed} + \\beta_0\\]\n- 즉, 속력에 따른 거리를 예측하기 위한 \\(\\beta_1, \\beta_0\\)를 추정! \\(\\to\\) \\((\\hat{\\beta_1}, \\hat{\\beta_0})\\)\n- 일반적으로, 알려진 단순선형회귀분석에서의 \\((\\hat{\\beta_1}, \\hat{\\beta_0})\\)을 구하는 방법!\n\\[\\hat {\\beta_0} = \\bar y - \\hat {\\beta_1}\\bar x\\]\n\\[\\hat {\\beta_1} = \\frac{S_{xy}}{S_{xx}} = \\frac{\\sum(x-\\bar x)(y-\\bar y)}{\\sum(x-\\bar x)^2}\\]\n- 공식유도법(나중에 시간되면 한번 풀어보세요!)\n\n\n\n- 실제로 저렇게 계산한 값과 R에서 회귀분석을 적합한 값이 일치한지 확인해보자\n\nx = cars$speed\ny = cars$dist\n\n\nbar_y = mean(y)\nbar_x = mean(x)\n\nbeta_1 = sum((x-bar_x)*(y-bar_y))/(sum((x-bar_x)^2))\n\nbeta_0 = bar_y - beta_1*bar_x\n\n\nbeta_1\n\n3.93240875912409\n\n\n\nbeta_0\n\n-17.579094890511\n\n\n- 즉, 이론상으로 속도에 따른 거리는 다음과 같이 설명할 수 있다\n\\[\\text{dist} \\approx  3.9324 \\times \\text{spped} -17.579... \\]\n\nlm1 = lm(y~x)\n\n\nlm1\n\n\nCall:\nlm(formula = y ~ x)\n\nCoefficients:\n(Intercept)            x  \n    -17.579        3.932  \n\n\n- 결과해석\n\n9.464^2\n\n89.567296\n\n\n\nsummary(lm1)\n\n\nCall:\nlm(formula = y ~ x)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-29.069  -9.525  -2.272   9.215  43.201 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -17.5791     6.7584  -2.601   0.0123 *  \nx             3.9324     0.4155   9.464 1.49e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15.38 on 48 degrees of freedom\nMultiple R-squared:  0.6511,    Adjusted R-squared:  0.6438 \nF-statistic: 89.57 on 1 and 48 DF,  p-value: 1.49e-12\n\n\n\nResiduals : 실제값과 예측값의 차이\n\n\\[\\varepsilon_i = \\hat{y_i} - y_i, \\quad \\varepsilon_i \\sim N(0, \\sigma^2)\\]\n\n잔차 제곱합은 다음과 같이 표현한다.\n\n\\[SSE =  \\sum_{i=1}^{n} \\varepsilon^2\\]\n\noptions(repr.plot.width = 8, repr.plot.height = 5)\nplot(y - lm1$fitted.values,main = \"잔차 plot\")\n\n\n\n\n\n\n\n\n\nplot(lm1,1)\n\n\n\n\n\n\n\n\n\nextra. subplots 그리는법\n\n\noptions(repr.plot.width = 12, repr.plot.height = 4)\npar(mfrow = c(1,2))\nplot(y - lm1$fitted.values,main = \"잔차 plot\")\nplot(lm1,1)\n\n\n\n\n\n\n\n\n\np-value? 검정통계량의 근거하여 적합한 모형의 유의미성을 검증하는 척도\n\n\nsummary(lm1)\n\n\nCall:\nlm(formula = y ~ x)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-29.069  -9.525  -2.272   9.215  43.201 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -17.5791     6.7584  -2.601   0.0123 *  \nx             3.9324     0.4155   9.464 1.49e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 15.38 on 48 degrees of freedom\nMultiple R-squared:  0.6511,    Adjusted R-squared:  0.6438 \nF-statistic: 89.57 on 1 and 48 DF,  p-value: 1.49e-12\n\n\n\n결과해석\n1 추정된 회귀계수 \\(\\hat{\\beta_1},\\hat{\\beta_0}\\)는 t-검정통계량의 근거한 p-value값을 보았을 때 0.05보다 작아 통계적으로 유의하다.\n2 결정계수값을 살펴본 결과 적합한 모형은 65% 정도의 설명력을 가지고 있다.\n3 또한, F-통계량의 근거한 p-value값을 보아도 생성된 모델은 통계적으로 유의하다.\n4 잔차 plot을 그려본 결과 오차항의 정규성과 독립성 가정에 위배되지 않았음\n\npar(mfrow=c(1,2))\nplot(lm1,1);plot(lm1,2)\n\n\n\n\n\n\n\n\n5 따라서, 우리가 적합한 모델은 속도에 따른 자동차의 주행거리를 설명하기에 적합한 모형이라고 할 수 있다.\n\n\n\n\nex2. adult(logistic)\n- 로지스틱 모형은 target 변수인 \\(y\\)에 대한 직접적 모형화가 아닌 \\(y\\)가 특정 범주에 포함될 확률을 모형화한다.\n- 임계치(threshole)를 정하고 어떤 범주에 포함될 확률이 임계치보다 높으면 0 or 1로 예측하는 분류 모형이다. (이진분류에서!)\n\n모형 유도\nstep1 : 0과 1사이의 값으로 예측해 주는 모형 설계\n\\[P(X) = \\frac{exp(\\beta_0+\\beta_1X)}{1+exp(\\beta_0+\\beta_1X)}, \\quad \\in (0,1)\\]\nstep2. odds, 배팅을 하는 분야에서 확률 대신 많이 쓰이는 측도\n\\[\\text{odds} = \\frac{P(X)}{1-P(x)}= {exp(\\beta_0 + \\beta_1X)}, \\quad \\in(0, \\infty)\\]\nstep3. logit, 배팅을하는 분야에서 확률 대신 많이 쓰이는 측도\n\\[\\text{logit} = \\log{\\frac{P(X)}{1-P(x)}}  = \\beta_0 + \\beta_1 x, \\quad \\in (-\\infty, \\infty)\\]\n즉, 우리는 로짓에서 보이는 \\(\\beta_0, \\beta_1\\)을 추정하는 것임\n\n\n실습, 주식 데이터\n\n#install.packages(\"ISLR\")\nlibrary(ISLR)\nlibrary(tidyverse)\n#names(Smarket)\n\n\nhead(Smarket)\n\n\n\nA data.frame: 6 × 9\n\n\n\nYear\nLag1\nLag2\nLag3\nLag4\nLag5\nVolume\nToday\nDirection\n\n\n\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;dbl&gt;\n&lt;fct&gt;\n\n\n\n\n1\n2001\n0.381\n-0.192\n-2.624\n-1.055\n5.010\n1.1913\n0.959\nUp\n\n\n2\n2001\n0.959\n0.381\n-0.192\n-2.624\n-1.055\n1.2965\n1.032\nUp\n\n\n3\n2001\n1.032\n0.959\n0.381\n-0.192\n-2.624\n1.4112\n-0.623\nDown\n\n\n4\n2001\n-0.623\n1.032\n0.959\n0.381\n-0.192\n1.2760\n0.614\nUp\n\n\n5\n2001\n0.614\n-0.623\n1.032\n0.959\n0.381\n1.2057\n0.213\nUp\n\n\n6\n2001\n0.213\n0.614\n-0.623\n1.032\n0.959\n1.3491\n1.392\nUp\n\n\n\n\n\n\n-데이터 설명\n\nlag\\(_i\\) : i번째 전 날의 smarket 주식 종가\ntoday : 오늘 주식 종가\nDirection : 주식이 올라갔는지, 떨어졌는지\nVolume : 거래량\n\n1 데이터셋 분할 7:3으로 분할\n\ntrain &lt;- Smarket %&gt;% sample_frac(0.7)\ntest &lt;- Smarket %&gt;% setdiff(train)\n\n\nglimpse(test)\n\nRows: 375\nColumns: 9\n$ Year      &lt;dbl&gt; 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, 2001, ~\n$ Lag1      &lt;dbl&gt; 0.381, 0.959, 1.392, -0.403, 1.303, -0.189, -0.562, 0.359, -~\n$ Lag2      &lt;dbl&gt; -0.192, 0.381, 0.213, 1.392, 0.027, -0.498, 0.701, -1.747, -~\n$ Lag3      &lt;dbl&gt; -2.624, -0.192, 0.614, 0.213, -0.403, 0.287, 0.680, 0.546, 0~\n$ Lag4      &lt;dbl&gt; -1.055, -2.624, -0.623, 0.614, 1.392, 1.303, -0.189, -0.562,~\n$ Lag5      &lt;dbl&gt; 5.010, -1.055, 1.032, -0.623, 0.213, 0.027, -0.498, 0.701, 0~\n$ Volume    &lt;dbl&gt; 1.19130, 1.29650, 1.44500, 1.40780, 1.23260, 1.09800, 1.2953~\n$ Today     &lt;dbl&gt; 0.959, 1.032, -0.403, 0.027, 0.287, 0.680, 0.546, -0.151, -0~\n$ Direction &lt;fct&gt; Up, Up, Down, Up, Up, Up, Up, Down, Down, Down, Down, Down, ~\n\n\n2 모형 적합\n\nlogit_fit &lt;-glm(Direction ~., data = train, \n                family = binomial(link = \"probit\")) ## 이진분류이므로 \"binomial\"이라고 기입\n\nWarning message:\n\"glm.fit: algorithm did not converge\"\nWarning message:\n\"glm.fit: fitted probabilities numerically 0 or 1 occurred\"\n\n\n3 예측\n\nlibrary(caret)\n\n필요한 패키지를 로딩중입니다: lattice\n\n\n다음의 패키지를 부착합니다: 'caret'\n\n\nThe following object is masked from 'package:purrr':\n\n    lift\n\n\n\n\n\npred &lt;-  ifelse(predict(logit_fit,test, type = \"response\") &gt; 0.5, \"Up\", \"Down\") %&gt;% as_factor()\n\n\nconfusionMatrix(factor(pred), factor(test$Direction))\n\nWarning message in confusionMatrix.default(factor(pred), factor(test$Direction)):\n\"Levels are not in the same order for reference and data. Refactoring data to match.\"\n\n\nConfusion Matrix and Statistics\n\n          Reference\nPrediction Down  Up\n      Down  185   0\n      Up      1 189\n                                          \n               Accuracy : 0.9973          \n                 95% CI : (0.9852, 0.9999)\n    No Information Rate : 0.504           \n    P-Value [Acc &gt; NIR] : &lt;2e-16          \n                                          \n                  Kappa : 0.9947          \n                                          \n Mcnemar's Test P-Value : 1               \n                                          \n            Sensitivity : 0.9946          \n            Specificity : 1.0000          \n         Pos Pred Value : 1.0000          \n         Neg Pred Value : 0.9947          \n             Prevalence : 0.4960          \n         Detection Rate : 0.4933          \n   Detection Prevalence : 0.4933          \n      Balanced Accuracy : 0.9973          \n                                          \n       'Positive' Class : Down            \n                                          \n\n\n\n\n정밀도, 재현율, 정확도\n- 위 네 가지는, 분류 모델의 성능 평가시 사용되는 척도이며 처음 접하는 사람들이 많이 헷갈려한다.\n- 위 예제는 4가지 지표에서 뛰어난 성능을 보이나 그렇지 않은 경우가 존재한다면?\n\nas.table(matrix(c(9644,23,252,81), nrow = 2))\n\n     A    B\nA 9644  252\nB   23   81\n\n\n- 정확도(accuracy)를 구해보자\n\n(9644+81)/(9644+23+252+81)\n\n0.9725\n\n\n- 오, 괜찮은 것 같다?\n\n그러나 여기에는 함정이 존재한다.(재현율)\n\n\n(81)/(252+81)\n\n0.243243243243243\n\n\n\n어라? 전체 B중에 예측모델이 B라고 예측한 것은 0.24..밖에 안되네?\n기업의 입장에서 보았을 때, 정확도보단 재현율이 더 중요한 지표임\n즉, 실제 참인 것 중에 예측모델이 참이라고 예측한 비율이 낮은 경우가 발생할 수 있음\n\n- 정밀도 : 모델이 참이라고 예측한 것 중, 실제 참인 것의 비율\n\n81/(23+81)\n\n0.778846153846154\n\n\n- 즉, 우리가 분류모델을 설계하고, 에측 성능을 판단할 때 단순히 정확도만 보고 판단하면 안 된다는 것!",
    "crumbs": [
      "Posts",
      "01. intro"
    ]
  },
  {
    "objectID": "posts/2024-03-28-01. intro.html#unsupervised-learning",
    "href": "posts/2024-03-28-01. intro.html#unsupervised-learning",
    "title": "01. intro",
    "section": "Unsupervised Learning",
    "text": "Unsupervised Learning\n- 설명변수 \\(X=(x_1, x_2, \\dots)\\)로 부터 비슷한 성질을 갖는 녀석들끼리 한 집단으로 묶는 것\n- 대표적인 알고리즘 : kmeans, dbscan, hdbscan 등등\n\nk-means\n1주어진 데이터를 k개의 클러스터로 묶는 알고리즘, 각 클러스터와 거리 차이의 분산을 최소화 하는 방식으로 동작\n2 허나 군집의 수, 가중치와 거리 정의가 어려우며, 사전에 주어진 목적이 없으므로 결과 해석이 어려움.\n3 또한 잡음이나 이상값의 영향을 받으며 초기 군집 수를 결정해야 한다는 단점이 있다.\n\n#install.packages(\"patchwork\")\n\n\n\nCode\noptions(repr.plot.res = 200)\n\np1 = ggplot(iris, \n       aes(Petal.Length, Petal.Width, color = Species)) + \n            geom_point()\n\np2 = ggplot(iris, \n       aes(Petal.Length, Petal.Width)) + \n            geom_point()\n\nlibrary(patchwork)\n\np1 + p2\n\n\n\n\n\n\n\n\n\n- 만약, 우리가 생성한 군집이 잘 생성되었다면? 완쪽과 같은 분포로 군집이 형성되어야 한다.\n\n\nCode\nic &lt;- kmeans(iris[,3:4], centers = 3)\n\niris$cluster &lt;- as.factor(ic$cluster)\n\np1 = ggplot(iris, \n       aes(Petal.Length, Petal.Width, color = Species)) + \n            geom_point()\n\np2 = ggplot(iris, \n       aes(Petal.Length, Petal.Width, color = cluster)) + \n            geom_point()\n\np1 + p2",
    "crumbs": [
      "Posts",
      "01. intro"
    ]
  },
  {
    "objectID": "posts/2023-08-19-00. Plotly test.html",
    "href": "posts/2023-08-19-00. Plotly test.html",
    "title": "00. Plotly test",
    "section": "",
    "text": "import\n\nimport plotly.express as ex\nimport plotly.express as px\nimport plotly.io as pio\npio.renderers.default = \"plotly_mimetype+notebook_connected\"\nimport numpy as np\nimport pandas as pd\n\n\ndf = pd.read_csv('https://raw.githubusercontent.com/kalilurrahman/datasets/main/mobilephonemktshare2020.csv')\ndf.head()\n\n\n\n\n\n\n\n\n\nDate\nSamsung\nApple\nHuawei\nXiaomi\nOppo\nMobicel\nMotorola\nLG\nOthers\nRealme\nGoogle\nNokia\nLenovo\nOnePlus\nSony\nAsus\n\n\n\n\n0\n2019-10\n31.49\n22.09\n10.02\n7.79\n4.10\n3.15\n2.41\n2.40\n9.51\n0.54\n2.35\n0.95\n0.96\n0.70\n0.84\n0.74\n\n\n1\n2019-11\n31.36\n22.90\n10.18\n8.16\n4.42\n3.41\n2.40\n2.40\n9.10\n0.78\n0.66\n0.97\n0.97\n0.73\n0.83\n0.75\n\n\n2\n2019-12\n31.37\n24.79\n9.95\n7.73\n4.23\n3.19\n2.50\n2.54\n8.13\n0.84\n0.75\n0.90\n0.87\n0.74\n0.77\n0.70\n\n\n3\n2020-01\n31.29\n24.76\n10.61\n8.10\n4.25\n3.02\n2.42\n2.40\n7.55\n0.88\n0.69\n0.88\n0.86\n0.79\n0.80\n0.69\n\n\n4\n2020-02\n30.91\n25.89\n10.98\n7.80\n4.31\n2.89\n2.36\n2.34\n7.06\n0.89\n0.70\n0.81\n0.77\n0.78\n0.80\n0.69\n\n\n\n\n\n\n\n\n\ndf.set_index(\"Date\").diff().\\\n  dropna().boxplot(backend = \"plotly\")",
    "crumbs": [
      "Posts",
      "00. Plotly test"
    ]
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site",
    "crumbs": [
      "About"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "edu1",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nMar 28, 2024\n\n\n00. jupyter lab 단축키 추가\n\n\nGC \n\n\n\n\nMar 26, 2024\n\n\n01. intro\n\n\nGC \n\n\n\n\nAug 19, 2023\n\n\n00. Plotly test\n\n\nGC \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2024-03-26-00. jupyter 단축키 추가법.html",
    "href": "posts/2024-03-26-00. jupyter 단축키 추가법.html",
    "title": "00. jupyter lab 단축키 추가",
    "section": "",
    "text": "intro\n- 예전엔 그냥 주피터에서 R을 쓸 때 %&gt;% 같은 파이프 연산자와 &lt;- 같은 변수 정의를 위한 단축키가 잘 작동되었는데 버전 문제인가? 이제는 적용되지 않더라….\n- 이것 때문에 하루를 날리고 끝내 방법을 찾음\n- 이제 단축키를 내 마음대로 추가할 수 있음 (너무 좋앙)\n\n\n단축키 추가법\n1 settings Editor -&gt; keyboard shortcuts 클릭!\n2 그럼 상단에 Json Setting Editor라고 눈 동그랗게 뜨고 보면 보임\n\n\n\n3 이제 저기로 들어가서 아래와 같은 json 코드를 삽입하자\n\n\n\n4 후. 이것 때문에 하루 다 날린 걸 생각하면 열이 받지만, 다시금 다양한 언어를 잘 활용할 줄 아는 것의 중요성을 느꼈다.\n5 ref\n\n\ntest\n\nlibrary(tidyverse)\n\n\nmpg %&gt;% ggplot(aes(x = hwy, y = cty, color = cyl)) +\n            geom_point(alpha = 0.5, size = 2) +\n            scale_color_viridis_c() +\n            theme_minimal()",
    "crumbs": [
      "Posts",
      "00. jupyter lab 단축키 추가"
    ]
  }
]